{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlmoD2Yw7dg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib.image import imread\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import scipy\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import cv2\n",
        "import moviepy.editor as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import glob\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0ICtUb2d7mYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWlpr99J7dg_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "modules18 = list(resnet18.children())[:-1]\n",
        "model = nn.Sequential(*modules18)\n",
        "flatten = nn.Flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWlCt8Do7dhA"
      },
      "outputs": [],
      "source": [
        "def extract_features_resnet18(video_path):\n",
        "    img_features = {}\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    print(\"Frames per second: \", fps)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    with tqdm(total=frame_count, desc=\"Extracting Features\") as pbar:\n",
        "        while video.isOpened():\n",
        "            ret, frame = video.read()\n",
        "            count += 1\n",
        "            if not ret:\n",
        "                break\n",
        "            img = frame\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (250, 250))\n",
        "            img = torch.Tensor(img)\n",
        "            img = img.permute(2, 0, 1)\n",
        "            img = img.unsqueeze(0)\n",
        "            features = model(img).view(512)\n",
        "            features = features.detach().numpy()\n",
        "            img_features[count] = features\n",
        "            pbar.update(1)\n",
        "            if count % 500 == 0:\n",
        "                pbar.set_postfix({\"Processed frames\": count})\n",
        "\n",
        "        video.release()\n",
        "        print(\"\\n\")\n",
        "        return img_features\n",
        "\n",
        "\n",
        "def eratosthenis(img_features, n):\n",
        "    prime_numbers = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n",
        "    segments = [[] for _ in range(n)]\n",
        "\n",
        "    for fn, fv in img_features.items():\n",
        "        frame_number = fn\n",
        "        assigned = False\n",
        "        for i in range(n):\n",
        "            if frame_number % prime_numbers[i] == 0:\n",
        "                segments[i].append(fv)\n",
        "                assigned = True\n",
        "                break\n",
        "        if not assigned:\n",
        "            segments[-1].append(fv)\n",
        "\n",
        "    return segments\n",
        "\n",
        "\n",
        "def optimal_k(feature_vectors):\n",
        "    dbi_scores = []\n",
        "    k_values = range(3, min(len(feature_vectors), 11))\n",
        "\n",
        "    for k in k_values:\n",
        "        gmm = GaussianMixture(n_components=k, random_state=0)\n",
        "        gmm.fit(feature_vectors)\n",
        "\n",
        "        dbi_score = davies_bouldin_score(\n",
        "            feature_vectors, gmm.predict(feature_vectors))\n",
        "        dbi_scores.append(dbi_score)\n",
        "\n",
        "    dbi_scores = np.array(dbi_scores)\n",
        "    index = np.argmin(dbi_scores)\n",
        "    optimal_k = k_values[index]\n",
        "\n",
        "    return optimal_k\n",
        "\n",
        "\n",
        "def cluster(data):\n",
        "    key_frames = []\n",
        "\n",
        "    k = optimal_k(data)\n",
        "    gmm = GaussianMixture(n_components=k)\n",
        "    gmm.fit(data)\n",
        "\n",
        "    centers = gmm.means_\n",
        "\n",
        "    for i in range(len(centers)):\n",
        "        key_array = centers[i]\n",
        "        distances = cdist(data, np.expand_dims(\n",
        "            key_array, axis=0), metric=\"euclidean\")\n",
        "        closest_index = np.argmin(distances)\n",
        "        closest_array = data[closest_index]\n",
        "        key_frames.append(closest_array)\n",
        "\n",
        "    return key_frames\n",
        "\n",
        "\n",
        "def generate_keyframes(img_features):\n",
        "    sets = eratosthenis(img_features, 5)\n",
        "\n",
        "    stage1 = []\n",
        "    stage2 = []\n",
        "    final_kf = []\n",
        "\n",
        "    print(\"Performing Clustering Stage-I:\\nSegments done: \", end=\"\")\n",
        "    for idx, set in enumerate(sets):\n",
        "        print(idx + 1, \" \", end=\"\")\n",
        "        var1 = cluster(set)\n",
        "\n",
        "        listcopy(var1, stage1)\n",
        "\n",
        "    print(\"\\nPerforming Clustering Stage-II \")\n",
        "    stage2 = cluster(stage1)\n",
        "\n",
        "    for i in stage2:\n",
        "        final_kf.append(frame_mapper(img_features, i))\n",
        "\n",
        "    final_kf.sort()\n",
        "\n",
        "    print(f\"Keyframes are {final_kf}\\n\")\n",
        "\n",
        "    return final_kf\n",
        "\n",
        "\n",
        "def listcopy(l1, l2):\n",
        "    for i in range(len(l1)):\n",
        "        l2.append(l1[i])\n",
        "\n",
        "\n",
        "def frame_mapper(dictionary, value):\n",
        "    for key, val in dictionary.items():\n",
        "        if np.array_equal(val, value):\n",
        "            return key\n",
        "\n",
        "\n",
        "def get_video_name_from_path(full_path):\n",
        "    path, filename = os.path.split(full_path)\n",
        "    name, extension = os.path.splitext(filename)\n",
        "\n",
        "    return name\n",
        "\n",
        "\n",
        "def calculate_similarity(feature_vector1, feature_vector2):\n",
        "    similarity = cosine_similarity([feature_vector1], [feature_vector2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "def boundary_determination(feature_vectors_dict, keyframes, initial_event_boundary_threshold):\n",
        "    total_frames = len(feature_vectors_dict)\n",
        "    max_total_length = int(total_frames * 0.15)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    feature_vectors = list(feature_vectors_dict.values())\n",
        "    merged_events = [(keyframe, keyframe) for keyframe in keyframes]\n",
        "    total_length = len(keyframes)\n",
        "    event_boundary_threshold = initial_event_boundary_threshold\n",
        "\n",
        "    while total_length < max_total_length:\n",
        "        next_events = [(start - 1, end + 1) for start, end in merged_events]\n",
        "        next_total_length = sum(end_frame - start_frame + 1 for start_frame, end_frame in next_events)\n",
        "        if next_total_length > max_total_length:\n",
        "            event_boundary_threshold *= 0.9\n",
        "        else:\n",
        "            event_boundary_threshold *= 1.1\n",
        "\n",
        "        merged_events = next_events\n",
        "        total_length = next_total_length\n",
        "\n",
        "    return merged_events,event_boundary_threshold\n",
        "\n",
        "\n",
        "\n",
        "def generate_summary_selection(total_frames, frame_ranges):\n",
        "    summary_selection = [0] * total_frames\n",
        "\n",
        "    for start, end in frame_ranges:\n",
        "        start = max(start, 0)\n",
        "        end = min(end, total_frames)\n",
        "        for i in range(start, end):\n",
        "            summary_selection[i] = 1\n",
        "\n",
        "    return summary_selection\n",
        "\n",
        "\n",
        "def evaluate(summary_selection, videoName, HOMEDATA):\n",
        "    gt_file = os.path.join(HOMEDATA, videoName + \".mat\")\n",
        "    gt_data = scipy.io.loadmat(gt_file)\n",
        "    user_score = gt_data.get(\"user_score\")\n",
        "    nFrames = user_score.shape[0]\n",
        "    nbOfUsers = user_score.shape[1]\n",
        "    if len(summary_selection) < nFrames:\n",
        "        warnings.warn(\n",
        "            \"Pad selection with %d zeros!\" % (nFrames - len(summary_selection))\n",
        "        )\n",
        "        summary_selection.extend([0] * (nFrames - len(summary_selection)))\n",
        "    elif len(summary_selection) > nFrames:\n",
        "        warnings.warn(\n",
        "            \"Crop selection (%d frames) to GT length\"\n",
        "            % (len(summary_selection) - nFrames)\n",
        "        )\n",
        "        summary_selection = summary_selection[:nFrames]\n",
        "    summary_indicator = np.array(\n",
        "        [1 if x > 0 else 0 for x in summary_selection])\n",
        "    user_intersection = np.zeros((nbOfUsers, 1))\n",
        "    user_union = np.zeros((nbOfUsers, 1))\n",
        "    user_length = np.zeros((nbOfUsers, 1))\n",
        "    f_measure = []\n",
        "\n",
        "    for userIdx in range(nbOfUsers):\n",
        "        gt_indicator = np.array(\n",
        "            [1 if x > 0 else 0 for x in user_score[:, userIdx]])\n",
        "\n",
        "        user_intersection[userIdx] = np.sum(gt_indicator * summary_indicator)\n",
        "        user_union[userIdx] = np.sum(\n",
        "            np.array([1 if x > 0 else 0 for x in gt_indicator + summary_indicator])\n",
        "        )\n",
        "        user_length[userIdx] = np.sum(gt_indicator)\n",
        "\n",
        "        if user_intersection[userIdx] > 0 or user_length[userIdx] > 0:\n",
        "            f_measure.append(\n",
        "                2\n",
        "                * user_intersection[userIdx]\n",
        "                / (user_length[userIdx] + user_intersection[userIdx])\n",
        "            )\n",
        "        else:\n",
        "            f_measure.append(0)\n",
        "    fscore = np.mean(f_measure)\n",
        "    print(\"f-score=\", fscore)\n",
        "    return fscore\n",
        "\n",
        "\n",
        "def save_details(file_path, video_details):\n",
        "    is_empty = os.stat(file_path).st_size == 0\n",
        "\n",
        "    with open(file_path, mode=\"a\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        if is_empty:\n",
        "            header = [\n",
        "                \"Video Name\",\n",
        "                \"Total Frames\",\n",
        "                \"Keyframes\",\n",
        "                \"Event Boundaries\",\n",
        "                \"F-Score\",\n",
        "            ]\n",
        "            writer.writerow(header)\n",
        "        writer.writerow(video_details)\n",
        "\n",
        "\n",
        "def output_summary(video_path, frame_ranges, output_path, video_name):\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    fps = video_clip.fps\n",
        "\n",
        "    clips = []\n",
        "\n",
        "    for start_frame, end_frame in frame_ranges:\n",
        "        clip = mp.VideoFileClip(video_path).subclip(\n",
        "            start_frame / fps, end_frame / fps)\n",
        "        clips.append(clip)\n",
        "\n",
        "    final_clip = mp.concatenate_videoclips(clips)\n",
        "    # output_path1 = video_name + \"_\" + output_path\n",
        "    final_clip.write_videofile(\n",
        "        output_path, codec=\"libx264\", audio_codec=\"aac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scGOTBTE7dhF"
      },
      "outputs": [],
      "source": [
        "folder_path = r\"/content/drive/MyDrive/Video_Summarization/videos\"\n",
        "video_files = glob.glob(\n",
        "    os.path.join(folder_path, \"*.mp4\")\n",
        ")\n",
        "for x,i in enumerate(video_files):\n",
        "  print(f\"Video {x}:{ get_video_name_from_path(i)}\")\n",
        "Done=[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "TNZ4HSFi7dhI",
        "outputId": "6b38ef63-ecd1-4c63-ce48-aa86ce1199b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video 3: Bearpark_climbing\n",
            "\n",
            "Frames per second:  25.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features:   1%|          | 28/3341 [00:04<08:28,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6e1c6e784ac8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Video {count+1}: {videoName}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features_resnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mkeyframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_keyframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-18ce2154cd3e>\u001b[0m in \u001b[0;36mextract_features_resnet18\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mimg_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "HOMEDATA = \"/content/drive/MyDrive/Video_Summarization/GT/\"\n",
        "event_boundary_threshold = 0.9985\n",
        "for count, video_path in enumerate(video_files):\n",
        "        videoName = get_video_name_from_path(video_path)\n",
        "\n",
        "        print(f\"Video {count+1}: {videoName}\\n\")\n",
        "        img_features = extract_features_resnet18(video_path)\n",
        "\n",
        "        keyframes = generate_keyframes(img_features)\n",
        "\n",
        "        event_boundaries,ebt = boundary_determination(\n",
        "            img_features, keyframes, event_boundary_threshold)\n",
        "\n",
        "        total_frames = len(list(img_features.values()))\n",
        "        summary_selection2 = generate_summary_selection(\n",
        "            total_frames, event_boundaries)\n",
        "        f_score = evaluate(summary_selection2, videoName, HOMEDATA)\n",
        "        num=0\n",
        "        for i in event_boundaries:\n",
        "          i=list(i)\n",
        "          down,up=i\n",
        "          # print(up)\n",
        "          num+=(up-down)\n",
        "        video_details = [videoName, f_score,\n",
        "                         total_frames, keyframes, event_boundaries,ebt,num]\n",
        "\n",
        "        save_details(\"/content/drive/MyDrive/Video_Summarization/video_summary_data.csv\", video_details)\n",
        "        # output_path=\"/content/drive/MyDrive/Video_Summarization/Summaries/\"+videoName+\"_summary.mp4\"\n",
        "        # output_summary(video_path, event_boundaries,output_path, videoName)\n",
        "        print(\"\\n----------------------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# print(f_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "video_path=video_files[0]\n",
        "    # if count%2==0 and count not in Done:\n",
        "videoName = get_video_name_from_path(video_path)\n",
        "print(f\"Video {count+1}: {videoName}\\n\")\n",
        "# img_features = extract_features_resnet18(video_path)\n",
        "keyframes = generate_keyframes(img_features)\n",
        "event_boundaries,ebt = boundary_determination(\n",
        "    img_features, keyframes, event_boundary_threshold)\n",
        "total_frames = len(list(img_features.values()))\n",
        "summary_selection2 = generate_summary_selection(\n",
        "    total_frames, event_boundaries)\n",
        "f_score = evaluate(summary_selection2, videoName, HOMEDATA)\n",
        "num=0\n",
        "for i in event_boundaries:\n",
        "  i=list(i)\n",
        "  down,up=i\n",
        "  # print(up)\n",
        "  num+=(up-down)\n",
        "video_details = [videoName, f_score,\n",
        "                 total_frames, keyframes, event_boundaries,ebt,num]\n",
        "save_details(\"/content/drive/MyDrive/Video_Summarization/video_summary_data.csv\", video_details)"
      ],
      "metadata": {
        "id": "Ie1fU0m3J4oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96AEy1j97dhO"
      },
      "outputs": [],
      "source": [
        "HOMEDATA = \"/content/drive/MyDrive/Video_Summarization/GT/\"\n",
        "event_boundary_threshold = 0.9985\n",
        "for count, video_path in enumerate(video_files):\n",
        "    if count%2!=0 and count not in Done:\n",
        "        videoName = get_video_name_from_path(video_path)\n",
        "\n",
        "        print(f\"Video {count+1}: {videoName}\\n\")\n",
        "        img_features = extract_features_resnet18(video_path)\n",
        "\n",
        "        keyframes = generate_keyframes(img_features)\n",
        "\n",
        "        event_boundaries,ebt = boundary_determination(\n",
        "            img_features, keyframes, event_boundary_threshold)\n",
        "\n",
        "        total_frames = len(list(img_features.values()))\n",
        "        summary_selection2 = generate_summary_selection(\n",
        "            total_frames, event_boundaries)\n",
        "        f_score = evaluate(summary_selection2, videoName, HOMEDATA)\n",
        "        num=0\n",
        "        for i in event_boundaries:\n",
        "          i=list(i)\n",
        "          down,up=i\n",
        "          # print(up)\n",
        "          num+=(up-down)\n",
        "        video_details = [videoName, f_score,\n",
        "                         total_frames, keyframes, event_boundaries,ebt,num]\n",
        "\n",
        "        save_details(\"/content/drive/MyDrive/Video_Summarization/video_summary_data.csv\", video_details)\n",
        "        # output_path=\"/content/drive/MyDrive/Video_Summarization/Summaries/\"+videoName+\"_summary.mp4\"\n",
        "        # output_summary(video_path, event_boundaries,output_path, videoName)\n",
        "        print(\"\\n----------------------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# print(f_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for count, video_path in enumerate(video_files):\n",
        "    if count==13 and count not in Done:\n",
        "        videoName = get_video_name_from_path(video_path)\n",
        "\n",
        "        print(f\"Video {count+1}: {videoName}\\n\")\n",
        "        img_features = extract_features_resnet18(video_path)\n",
        "\n",
        "        keyframes = generate_keyframes(img_features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(f_score)"
      ],
      "metadata": {
        "id": "19C-abhDS---"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HOMEDATA = \"/content/drive/MyDrive/Video_Summarization/GT/\"\n",
        "event_boundary_threshold = 0.9985\n",
        "event_boundaries,ebt = boundary_determination(img_features, keyframes, event_boundary_threshold)\n",
        "total_frames = len(list(img_features.values()))\n",
        "\n",
        "summary_selection2 = generate_summary_selection(total_frames, event_boundaries)\n",
        "f_score = evaluate(summary_selection2, videoName, HOMEDATA)\n",
        "\n",
        "num=0\n",
        "\n",
        "for i in event_boundaries:\n",
        "\n",
        "        i=list(i)\n",
        "\n",
        "        down,up=i\n",
        "\n",
        "        # print(up)\n",
        "\n",
        "        num+=(up-down)\n",
        "\n",
        "video_details = [videoName, f_score, total_frames, keyframes, event_boundaries,ebt,num]\n",
        "# save_details(\"/content/drive/MyDrive/Video_Summarization/video_summary_data.csv\", video_details)\n",
        "output_path=\"/content/drive/MyDrive/Video_Summarization/Summaries/\"+videoName+\"_summary.mp4\"\n",
        "output_summary(video_path, event_boundaries,output_path, videoName)\n",
        "print(\"\\n----------------------------------------------------------------------------------------------------------------------\\n\")\n"
      ],
      "metadata": {
        "id": "CLSCvWUmTI_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HOMEDATA = \"/content/drive/MyDrive/Video_Summarization/GT/\"\n",
        "event_boundary_threshold = 0.9985\n",
        "for count, video_path in enumerate(video_files):\n",
        "    if count==7 and count not in Done:\n",
        "        videoName = get_video_name_from_path(video_path)\n",
        "\n",
        "        print(f\"Video {count+1}: {videoName}\\n\")\n",
        "        # img_features = extract_features_resnet18(video_path)\n",
        "\n",
        "        keyframes = [125, 328, 413, 427, 539, 566, 703, 712, 775, 959]\n",
        "\n",
        "        # event_boundaries,ebt = boundary_determination(\n",
        "        #     img_features, keyframes, event_boundary_threshold)\n",
        "        event_boundaries=[(115, 135), (318, 338), (403, 423), (417, 437), (529, 549), (556, 576), (693, 713), (702, 722), (765, 785), (949, 969)]\n",
        "        # total_frames = len(list(img_features.values()))\n",
        "        summary_selection2 = generate_summary_selection(\n",
        "            total_frames, event_boundaries)\n",
        "        f_score = evaluate(summary_selection2, videoName, HOMEDATA)\n",
        "        num=0\n",
        "        for i in event_boundaries:\n",
        "          i=list(i)\n",
        "          down,up=i\n",
        "          # print(up)\n",
        "          num+=(up-down)\n",
        "        video_details = [videoName, f_score,\n",
        "                         total_frames, keyframes, event_boundaries,ebt,num]\n",
        "\n",
        "        save_details(\"/content/drive/MyDrive/Video_Summarization/video_summary_data.csv\", video_details)\n",
        "        output_path=\"/content/drive/MyDrive/Video_Summarization/Summaries/\"+videoName+\"_summary.mp4\"\n",
        "        output_summary(video_path, event_boundaries,output_path, videoName)\n",
        "        print(\"\\n----------------------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_zZ_GjJcXq3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "LqflfN_QY4U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4s4epzTJY6m_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}